
Name:
Last 4 digits ID:
Computer IP address:
CSE 6331, Cloud Computing					


Quiz Q4i6, Summer 2015   (c) DL, UTA, 2015


  C&P means copy and paste only those relevant lines from your program(s) into this quiz.


 1. Get first sheet from your GTA.

 2. Get files from this same folder.
   
 3. Name your program with your name and last digits of your ID.

 4. This Dataset has consumer product recalls for the last few years. 
    We want to know which products, where, and when have the most recalls and whether some products
    are getting worse (more recalls).	

 5. Rename it to your name, .csv (you may "clean" this file if needed)

 6. Transfer it to a cloud provider, as a file

The remaining should be done, exclusivly, on a cloud service provider, using Hadoop (or MapReduce):

 7. Create a web front end to allow selecting a product sub category (for example "computers"),   
    and a state name ("for example "Texas"),
    and for every year (each year) show the number of recalls

 7.1 C&P to list, the number of recalls for each year at that state, for that "product" for that year

 7.2 Show to GTA

 8. We want to know which products (sub category) have had a 20% increase in recalls, from one year 
    to the next year (2014 compared to 2013)

 8.1 Show to GTA

 9. We want to know which products are getting worse, in each state, that is:
    for each year, which state that year had the most recalls?
    Please use three instances of Hadoop. Each Instance and mapper should print the time it 
    starts and it's IP address. 

 9.1 Show to GTA

 10. Submit this quiz
     

 11. When complete, return (send) this quiz
    If you finish early, send this immediately, otherwise send 
    on-time. 


Command:

hadoop jar /home/hadoop/hadoop-install/contrib/streaming/hadoop-streaming-1.2.1.jar -input /input/harish_kamuju4 -file /home/kamuju_harish_gmail_com/a6/mapper.py -mapper /home/kamuju_harish_gmail_com/a6/mapper.py -file /home/kamuju_harish_gmail_com/a6/reducer.py -reducer /home/kamuju_harish_gmail_com/a6/reducer.py -output /output1/




def read_input(file):
    for line in file:
        # split the line
        yield line.split(',')
def mapper():
    data = read_input(sys.stdin)
    for line in data:
       print line

def reducer():
# input comes from STDIN
task1 = {}


columns = ['Report No.', 'Report Date', 'Sent to Manufacturer / Importer / Private Labeler', 'Publication Date', 'Category of Submitter', 'Product Description', 'Product Category', 'Product Sub Category', 'Product Type', 'Product Code', 'Manufacturer / Importer / Private Labeler Name', 'Brand', 'Model Name or Number', 'Serial Number', 'UPC', 'Date Manufactured', 'Manufacturer Date Code', 'Retailer', 'Retailer State', 'Purchase Date', 'Purchase Date Is Estimate', 'Incident Description', 'City', 'State', 'ZIP', 'Location', '(Primary) Victim Severity', "(Primary) Victim's Gender", 'My Relation To The (Primary) Victim', "(Primary) Victim's Age (years)", 'Submitter Has Product', 'Product Was Damaged Before Incident', 'Damage Description', 'Damage Repaired', 'Product Was Modified Before Incident', 'Have You Contacted The Manufacturer', 'If Not Do You Plan To', 'Answer Explanation', 'Company Comments', 'Associated Report Numbers\r\n']

st = datetime.datetime.now()
count = 1
for line in sys.stdin:
    # remove leading and trailing whitespace
    line = line.strip()
    prosub = row[7] #Product Sub Category
    year = row[1] #Report Date
    state = row[23] #State
    product = row[8] #Product Type
    sentback = row[2] #'Sent to Manufacturer / Importer / Private Labeler'
    try:
        task1[prosub,state,year].append()
    except:
        task1[prosub,state,year] = [sentback]
    
    try:
        task1[prosub,state,year].append()
    except:
        task1[prosub,state,year] = [sentback]
        
et = datetime.datetime.now()
#output the data to a file in prosub,state,year and sentback format
for val in task1:
    print str(task1[val])+","+str(val)
    
#Takes the output file from the aws directory which was generated by the hadoop mapreduce and displays based on user request.
#Created in Django. 

#Creates key for the filename         
def createkey(filename):
    newkey = Key(buck)
    newkey.key = filename
    return newkey
    
def dynoresult(request):
    prosub = request.GET.get("prosub")
    state= request.GET.get("state")
    year = request.GET.get("year")
    response.write('''<div align="center"><h1> List of records with the search query</h1><br>''')
    
    newkey = createkey('harish_kamuju4.csv') 
    newkey.get_contents_to_filename('temp.csv')
    fps3 = open('temp.csv','r')
    alldata = csv.reader(fps3,delimiter=',')
    #prosub,state,year,sentback = row[0],row[1],row[2],row[3]
    response.write('''<br><table border="1" ><tr>
<td>State</td><td>Sub Product</td><td><Year></td></tr>''')   
    for row in alldata:
        
        if prosub.find(str(row[1])) or year.find(str(row[0])) or state.find(str(row[2])):
	    response.write('''<tr>
            <td>'''+str(row[1])+'''</td><td>'''+str(row[0])+'''</td><td>'''+str(row[2])+
            '''</td></tr>''')

'''We want to know which products (sub category) have had a 20% increase in recalls, from one year 
    to the next year (2014 compared to 2013)'''
    products = {}
    for row in alldata:
        if row[2] == '2014':
           try:
              products[row[2]].append(row[0])
           except:
              products[row[2]] = row[0]
           
    

    response.write('''</div>''')   
    return response
    


